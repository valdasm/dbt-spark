target:
  type: spark
  host: "{{ env_var('DBT_DATABRICKS_HOST_NAME') }}"
  cluster: "{{ env_var('DBT_DATABRICKS_CLUSTER_NAME') }}"
  authMethod: azureOAuth
  oauth_client_id: "{{ env_var('DBT_OAUTH_CLIENT_ID') }}"
  oauth_client_secret: "{{ env_var('DBT_OAUTH_CLIENT_SECRET') }}"
  oauth_client_authority: "{{ env_var('DBT_OAUTH_CLIENT_AUTHORITY') }}"
  method: odbc
  driver: "{{ env_var('ODBC_DRIVER') }}"
  port: 443
  schema: "analytics_{{ var('_dbt_random_suffix') }}"
  connect_retries: 5
  connect_timeout: 60
projects:
  - overrides: incremental
    paths:
      "models/incremental.sql":
        materialized: incremental
        body: "select * from {{ source('raw', 'seed') }}"
    facts:
      base:
        rowcount: 10
      added:
        rowcount: 20
  - overrides: snapshot_strategy_check_cols
    dbt_project_yml: &file_format_delta
      # we're going to UPDATE the seed tables as part of testing, so we must make them delta format
      seeds:
        dbt_test_project:
          file_format: delta
      snapshots:
        dbt_test_project:
          file_format: delta
  - overrides: snapshot_strategy_timestamp
    dbt_project_yml: *file_format_delta
sequences:
  test_dbt_empty: empty

